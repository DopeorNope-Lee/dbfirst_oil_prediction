{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "\n",
    "import dateutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import timm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_from_csv(filename):\n",
    "    return pd.read_csv(filename,encoding='utf-8').rename(columns=lambda x:x.strip())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET = \"./경유1train.csv\"\n",
    "TEST_DATASET =\"./경유1test.csv\"\n",
    "VALIDATION_DATASET = \"./경유1valid.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = dataframe_from_csv(TRAIN_DATASET)\n",
    "TRAIN.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "VALID = dataframe_from_csv(VALIDATION_DATASET)\n",
    "VALID.reset_index(drop=True,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008년04월15일</td>\n",
       "      <td>1585.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008년04월16일</td>\n",
       "      <td>1600.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008년04월17일</td>\n",
       "      <td>1594.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008년04월18일</td>\n",
       "      <td>1602.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008년04월19일</td>\n",
       "      <td>1606.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date    price\n",
       "0  2008년04월15일  1585.35\n",
       "1  2008년04월16일  1600.81\n",
       "2  2008년04월17일  1594.53\n",
       "3  2008년04월18일  1602.15\n",
       "4  2008년04월19일  1606.71"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021년07월01일</td>\n",
       "      <td>1403.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021년07월02일</td>\n",
       "      <td>1405.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021년07월03일</td>\n",
       "      <td>1406.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021년07월04일</td>\n",
       "      <td>1407.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021년07월05일</td>\n",
       "      <td>1409.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date    price\n",
       "0  2021년07월01일  1403.07\n",
       "1  2021년07월02일  1405.02\n",
       "2  2021년07월03일  1406.75\n",
       "3  2021년07월04일  1407.44\n",
       "4  2021년07월05일  1409.22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VALID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 형식으로 변환\n",
    "\n",
    "VALID['date']=VALID['date'].replace('(.*)년(.*)', r'\\1-\\2', regex=True)\n",
    "VALID['date']=VALID['date'].replace('(.*)월(.*)', r'\\1-\\2', regex=True)\n",
    "VALID['date']=VALID['date'].replace('(.*)일(.*)', r'\\1-\\2', regex=True)\n",
    "\n",
    "TRAIN['date']=TRAIN['date'].replace('(.*)년(.*)', r'\\1-\\2', regex=True)\n",
    "TRAIN['date']=TRAIN['date'].replace('(.*)월(.*)', r'\\1-\\2', regex=True)\n",
    "TRAIN['date']=TRAIN['date'].replace('(.*)일(.*)', r'\\1-\\2', regex=True)\n",
    "\n",
    "\n",
    "TRAIN['date']=pd.to_datetime(TRAIN['date'])\n",
    "VALID['date']=pd.to_datetime(VALID['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = TRAIN.shape[0]\n",
    "N_VALID= VALID.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP_FIELD = \"date\"\n",
    "ATTACK_FIELD = \"price\"\n",
    "VALID_COLUMNS_IN_TRAIN_DATASET='price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_GIVEN = 12\n",
    "WINDOW_SIZE = WINDOW_GIVEN + 1\n",
    "EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-04-15</td>\n",
       "      <td>1585.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-04-16</td>\n",
       "      <td>1600.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-04-17</td>\n",
       "      <td>1594.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-04-18</td>\n",
       "      <td>1602.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-04-19</td>\n",
       "      <td>1606.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4820</th>\n",
       "      <td>2021-06-26</td>\n",
       "      <td>1392.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4821</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>1393.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4822</th>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>1395.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4823</th>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>1398.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4824</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>1399.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4825 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date    price\n",
       "0    2008-04-15  1585.35\n",
       "1    2008-04-16  1600.81\n",
       "2    2008-04-17  1594.53\n",
       "3    2008-04-18  1602.15\n",
       "4    2008-04-19  1606.71\n",
       "...         ...      ...\n",
       "4820 2021-06-26  1392.56\n",
       "4821 2021-06-27  1393.61\n",
       "4822 2021-06-28  1395.65\n",
       "4823 2021-06-29  1398.26\n",
       "4824 2021-06-30  1399.91\n",
       "\n",
       "[4825 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class InnerConv1DBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters: int, h: float, kernel_size: int, neg_slope: float = .01, dropout: float = .5,\n",
    "                 **kwargs):\n",
    "        if filters <= 0 or h <= 0:\n",
    "            raise ValueError('filters and h must be positive')\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv1d = tf.keras.layers.Conv1D(max(round(h * filters), 1), kernel_size, padding='same')\n",
    "        self.leakyrelu = tf.keras.layers.LeakyReLU(neg_slope)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.conv1d2 = tf.keras.layers.Conv1D(filters, kernel_size, padding='same')\n",
    "        self.tanh = tf.keras.activations.tanh\n",
    "\n",
    "    def call(self, input_tensor, training=None):\n",
    "        x = self.conv1d(input_tensor)\n",
    "        x = self.leakyrelu(x)\n",
    "\n",
    "        if training:\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        x = self.conv1d2(x)\n",
    "        x = self.tanh(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SCIBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, features: int, kernel_size: int, h: int, name='sciblock', **kwargs):\n",
    "        \"\"\"\n",
    "        :param features: number of features in the output\n",
    "        :param kernel_size: kernel size of the convolutional layers\n",
    "        :param h: scaling factor for convolutional module\n",
    "        \"\"\"\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.features = features\n",
    "        self.kernel_size = kernel_size\n",
    "        self.h = h\n",
    "\n",
    "        self.conv1ds = {k: InnerConv1DBlock(filters=self.features, h=self.h, kernel_size=self.kernel_size, name=k)\n",
    "                        for k in ['psi', 'phi', 'eta', 'rho']}  # regularize?\n",
    "\n",
    "    def call(self, inputs):\n",
    "        F_odd, F_even = inputs[:, ::2], inputs[:, 1::2]\n",
    "\n",
    "        # Interactive learning as described in the paper\n",
    "        F_s_odd = F_odd * tf.math.exp(self.conv1ds['phi'](F_even))\n",
    "        F_s_even = F_even * tf.math.exp(self.conv1ds['psi'](F_odd))\n",
    "\n",
    "        F_prime_odd = F_s_odd + self.conv1ds['rho'](F_s_even)\n",
    "        F_prime_even = F_s_even - self.conv1ds['eta'](F_s_odd)\n",
    "\n",
    "        return F_prime_odd, F_prime_even\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'features': self.features, 'kernel_size': self.kernel_size, 'h': self.h})\n",
    "        return config\n",
    "\n",
    "\n",
    "class Interleave(tf.keras.layers.Layer):\n",
    "    \"\"\"A layer used to reverse the even-odd split operation.\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def _interleave(self, slices):\n",
    "        if not slices:\n",
    "            return slices\n",
    "        elif len(slices) == 1:\n",
    "            return slices[0]\n",
    "\n",
    "        mid = len(slices) // 2\n",
    "        even = self._interleave(slices[:mid])\n",
    "        odd = self._interleave(slices[mid:])\n",
    "\n",
    "        shape = tf.shape(even)\n",
    "        return tf.reshape(tf.stack([even, odd], axis=3), (shape[0], shape[1] * 2, shape[2]))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self._interleave(inputs)\n",
    "\n",
    "\n",
    "class SCINet(tf.keras.layers.Layer):\n",
    "    def __init__(self, horizon: int, features: int, levels: int, h: int, kernel_size: int,\n",
    "                 kernel_regularizer=None, activity_regularizer=None, name='scinet', **kwargs):\n",
    "        \"\"\"\n",
    "        :param horizon: number of time stamps in output\n",
    "        :param levels: height of the binary tree + 1\n",
    "        :param h: scaling factor for convolutional module in each SCIBlock\n",
    "        :param kernel_size: kernel size of convolutional module in each SCIBlock\n",
    "        :param kernel_regularizer: kernel regularizer for the fully connected layer at the end\n",
    "        :param activity_regularizer: activity regularizer for the fully connected layer at the end\n",
    "        \"\"\"\n",
    "        if levels < 1:\n",
    "            raise ValueError('Must have at least 1 level')\n",
    "\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.horizon = horizon\n",
    "        self.features = features\n",
    "        self.levels = levels\n",
    "        self.h = h\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.interleave = Interleave()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "        # tree of sciblocks\n",
    "        self.sciblocks = [SCIBlock(features=features, kernel_size=self.kernel_size, h=self.h)\n",
    "                          for _ in range(2 ** self.levels - 1)]\n",
    "        self.dense = tf.keras.layers.Dense(\n",
    "            self.horizon * features,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            activity_regularizer=activity_regularizer\n",
    "        )\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if input_shape[1] / 2 ** self.levels % 1 != 0:\n",
    "            raise ValueError(f'timestamps {input_shape[1]} must be evenly divisible by a tree with '\n",
    "                             f'{self.levels} levels')\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # cascade input down a binary tree of sci-blocks\n",
    "        lvl_inputs = [inputs]  # inputs for current level of the tree\n",
    "        for i in range(self.levels):\n",
    "            i_end = 2 ** (i + 1) - 1\n",
    "            i_start = i_end - 2 ** i\n",
    "            lvl_outputs = [output for j, tensor in zip(range(i_start, i_end), lvl_inputs)\n",
    "                           for output in self.sciblocks[j](tensor)]\n",
    "            lvl_inputs = lvl_outputs\n",
    "\n",
    "        x = self.interleave(lvl_outputs)\n",
    "        x += inputs\n",
    "\n",
    "        # not sure if this is the correct way of doing it. The paper merely said to use a fully connected layer to\n",
    "        # produce an output. Can't use TimeDistributed wrapper. It would force the layer's timestamps to match that of\n",
    "        # the input -- something SCINet is supposed to solve\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        x = tf.reshape(x, (-1, self.horizon, self.features))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'horizon': self.horizon, 'levels': self.levels})\n",
    "        return config\n",
    "\n",
    "\n",
    "class StackedSCINet(tf.keras.layers.Layer):\n",
    "    \"\"\"Layer that implements StackedSCINet as described in the paper.\n",
    "    When called, outputs a tensor of shape (K, -1, n_steps, n_features) containing the outputs of all K internal\n",
    "    SCINets (e.g., output[k-1] is the output of the kth SCINet, where k is in [1, ..., K]).\n",
    "    To use intermediate supervision, pass the layer's output to StackedSCINetLoss as a separate model output.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, horizon: int, features: int, stacks: int, levels: int, h: int, kernel_size: int,\n",
    "                 kernel_regularizer=None, activity_regularizer=None, name='stacked_scinet', **kwargs):\n",
    "        \"\"\"\n",
    "        :param horizon: number of time stamps in output\n",
    "        :param stacks: number of stacked SCINets\n",
    "        :param levels: number of levels for each SCINet\n",
    "        :param h: scaling factor for convolutional module in each SCIBlock\n",
    "        :param kernel_size: kernel size of convolutional module in each SCIBlock\n",
    "        :param kernel_regularizer: kernel regularizer for each SCINet\n",
    "        :param activity_regularizer: activity regularizer for each SCINet\n",
    "        \"\"\"\n",
    "        if stacks < 2:\n",
    "            raise ValueError('Must have at least 2 stacks')\n",
    "\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.stacks = stacks\n",
    "        self.scinets = [SCINet(horizon=horizon, features=features, levels=levels, h=h,\n",
    "                               kernel_size=kernel_size, kernel_regularizer=kernel_regularizer,\n",
    "                               activity_regularizer=activity_regularizer) for _ in range(stacks)]\n",
    "\n",
    "    def call(self, inputs):  # sample_weights=None\n",
    "        outputs = []\n",
    "        for scinet in self.scinets:\n",
    "            x = scinet(inputs)\n",
    "            outputs.append(x)  # keep each stack's output for intermediate supervision\n",
    "            inputs = tf.concat([x, inputs[:, x.shape[1]:, :]], axis=1)  # X_hat_k concat X_(t-(T-tilda)+1:t)\n",
    "        return tf.stack(outputs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'stacks': self.stacks})\n",
    "        return config\n",
    "\n",
    "\n",
    "class Identity(tf.keras.layers.Layer):\n",
    "    \"\"\"Identity layer used solely for the purpose of naming model outputs and properly displaying outputs when plotting\n",
    "    some multi-output models.\n",
    "    Returns input without changing them.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.identity(inputs)\n",
    "\n",
    "\n",
    "class StackedSCINetLoss(tf.keras.losses.Loss):\n",
    "    \"\"\"Compute loss for a Stacked SCINet via intermediate supervision.\n",
    "    `loss = sum of mean normalised difference between each stack's output and ground truth`\n",
    "    `y_pred` should be the output of a StackedSCINet layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name='stacked_scienet_loss', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        stacked_outputs = y_pred\n",
    "        horizon = stacked_outputs.shape[2]\n",
    "\n",
    "        errors = stacked_outputs - y_true\n",
    "        loss = tf.linalg.normalize(errors, axis=3)[1]\n",
    "        loss = tf.reduce_sum(loss, 2)\n",
    "        loss /= horizon\n",
    "        loss = tf.reduce_sum(loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "# class NetConcatenate(tf.keras.layer.Layer):\n",
    "#     def __init__(self, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.concatenate = tf.keras.layers.Concatenate(axis=1)\n",
    "#\n",
    "#     def call(self, intermediates, inputs):\n",
    "#         return self.concatenate([intermediates, inputs[:, intermediates.shape[1]:, :]])\n",
    "\n",
    "\n",
    "def make_simple_scinet(input_shape, horizon: int, L: int, h: int, kernel_size: int, learning_rate: float,\n",
    "                       kernel_regularizer=None, activity_regularizer=None, diagram_path=None):\n",
    "    \"\"\"Compiles a simple SCINet and saves model diagram if given a path.\n",
    "    Intended to be a demonstration of simple model construction. See paper for details on the hyperparameters.\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(input_shape[1], input_shape[2]), name='inputs'),\n",
    "        SCINet(horizon, features=input_shape[-1], levels=L, h=h, kernel_size=kernel_size,\n",
    "               kernel_regularizer=kernel_regularizer, activity_regularizer=activity_regularizer)\n",
    "    ])\n",
    "\n",
    "    model.summary()\n",
    "    if diagram_path:\n",
    "        tf.keras.utils.plot_model(model, to_file=diagram_path, show_shapes=True)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='mse',\n",
    "                  metrics=['mse', 'mae']\n",
    "                  )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_simple_stacked_scinet(input_shape, horizon: int, K: int, L: int, h: int, kernel_size: int,\n",
    "                               learning_rate: float, kernel_regularizer=None, activity_regularizer=None,\n",
    "                               diagram_path=None):\n",
    "    \"\"\"Compiles a simple StackedSCINet and saves model diagram if given a path.\n",
    "    Intended to be a demonstration of simple model construction. See paper for details on the hyperparameters.\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=(input_shape[1], input_shape[2]), name='lookback_window')\n",
    "    x = StackedSCINet(horizon=horizon, features=input_shape[-1], stacks=K, levels=L, h=h,\n",
    "                      kernel_size=kernel_size, kernel_regularizer=kernel_regularizer,\n",
    "                      activity_regularizer=activity_regularizer)(inputs)\n",
    "    outputs = Identity(name='outputs')(x[-1])\n",
    "    intermediates = Identity(name='intermediates')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=[outputs, intermediates])\n",
    "\n",
    "    model.summary()\n",
    "    if diagram_path:\n",
    "        tf.keras.utils.plot_model(model, to_file=diagram_path, show_shapes=True)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss={\n",
    "                      # 'outputs': 'mse',\n",
    "                      'intermediates': StackedSCINetLoss()\n",
    "                  },\n",
    "                  metrics={'outputs': ['mse', 'mae']}\n",
    "                  )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametres\n",
    "degree_of_differencing = 0\n",
    "look_back_window, horizon = 184, 60\n",
    "batch_size = 16\n",
    "learning_rate = 9e-3\n",
    "h, kernel_size, L, K = 4, 5, 3, 2\n",
    "l1, l2 = 0.001, 0.1\n",
    "# split_strides = look_back_window + horizon\n",
    "split_strides = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, output_shape):\n",
    "    inputs = tf.keras.Input(shape=(input_shape[1], input_shape[2]), name='inputs')\n",
    "    # x = SciNet(horizon, levels=L, h=h, kernel_size=kernel_size)(inputs)\n",
    "    # model = tf.keras.Model(inputs, x)\n",
    "    targets = tf.keras.Input(shape=(output_shape[1], output_shape[2]), name='targets')\n",
    "    predictions = StackedSCINet(horizon=horizon, features=input_shape[-1], stacks=K, levels=L, h=h,\n",
    "                                kernel_size=kernel_size,\n",
    "                                regularizer=(l1, l2))(inputs, targets)\n",
    "    model = tf.keras.Model(inputs=[inputs, targets], outputs=predictions)\n",
    "\n",
    "    model.summary()\n",
    "    tf.keras.utils.plot_model(model, to_file='modelDiagram.png', show_shapes=True)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mse',\n",
    "                  metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "    return model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9f122e37c82151bf9f34d3eff46fea91e08eb65de67b9d89caea98024846b0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
